# Runner Air Planner - ML Model Data Pipeline

Pipeline de datos y modelo de Machine Learning que predice el mejor momento para salir a correr en Madrid basÃ¡ndose en la calidad del aire y condiciones meteorolÃ³gicas.

## ğŸ¯ Objetivo

Crear un dataset estructurado con **mÃ­nimo 1000 registros** y entrenar un modelo ML que combine:
- **Calidad del aire** por estaciÃ³n (NOâ‚‚, Oâ‚ƒ, PM10, PM2.5, etc.)
- **Condiciones meteorolÃ³gicas** (temperatura, humedad, viento)
- **Features temporales** (hora, dÃ­a semana, mes)
- **Features de sinergia** (interacciones entre variables)

## ğŸš€ Inicio RÃ¡pido con Docker

### Levantar la aplicaciÃ³n

```bash
# Construir y levantar (primera vez)
docker-compose up -d --build

# Ver logs
docker-compose logs -f

# La app estarÃ¡ disponible en http://localhost:8501
```

### Comandos Ãºtiles

```bash
# Recopilar datos
docker-compose exec app poetry run collect --accumulate

# Entrenar modelo (cuando tengas 1000+ registros)
docker-compose exec app poetry run train

# Hacer predicciones
docker-compose exec app poetry run predict

# Abrir shell en el contenedor
docker-compose exec app bash

# Detener
docker-compose down
```

### Desarrollo con hot-reload

```bash
docker-compose -f docker-compose.dev.yml up
```

## ğŸ“¦ InstalaciÃ³n con Poetry (Local)

```bash
# Instalar Poetry
curl -sSL https://install.python-poetry.org | python3 -

# Instalar dependencias
poetry install

# Activar entorno
poetry shell
```

## ğŸ—ï¸ Estructura del Proyecto

```
runner-air-planner/
â”œâ”€â”€ src/runner_air_planner/
â”‚   â”œâ”€â”€ data_pipeline/          # Pipeline de datos para ML
â”‚   â”‚   â”œâ”€â”€ ingest_madrid_air.py    # Descarga datos calidad aire
â”‚   â”‚   â”œâ”€â”€ weather.py              # Cliente Open-Meteo
â”‚   â”‚   â”œâ”€â”€ master_data.py          # Datos maestros
â”‚   â”‚   â”œâ”€â”€ data_collector.py       # Clase principal que integra todo
â”‚   â”‚   â”œâ”€â”€ accumulate_data.py      # AcumulaciÃ³n de datos histÃ³ricos
â”‚   â”‚   â””â”€â”€ cli_collect.py          # CLI para recopilar datos
â”‚   â”œâ”€â”€ ml/                      # Modelos de Machine Learning
â”‚   â”‚   â”œâ”€â”€ model.py                # DefiniciÃ³n del modelo
â”‚   â”‚   â”œâ”€â”€ train.py                # Entrenamiento
â”‚   â”‚   â””â”€â”€ predict.py              # Predicciones
â”‚   â””â”€â”€ frontend/                # Interfaz de usuario
â”‚       â””â”€â”€ streamlit_app.py        # Dashboard Streamlit
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ collect_multiple_days.py
â”œâ”€â”€ data/                           # Datasets y modelos
â”‚   â”œâ”€â”€ ml_dataset_accumulated.csv
â”‚   â””â”€â”€ models/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ pyproject.toml                  # GestiÃ³n con Poetry
```

## ğŸ“Š Uso

### 1. Recopilar datos

```bash
# Con Docker
docker-compose exec app poetry run collect --accumulate

# Con Poetry local
poetry run collect --accumulate
```

### 2. Acumular hasta 1000+ registros

La API de Madrid solo devuelve datos del dÃ­a actual (~300-400 registros). Para alcanzar 1000+:

```bash
# Ejecutar varias veces (cada 1-2 horas)
docker-compose exec app poetry run collect --accumulate

# O automÃ¡tico
python scripts/collect_multiple_days.py --min-records 1000 --interval-hours 1
```

### 3. Entrenar modelo

```bash
docker-compose exec app poetry run train
```

### 4. Hacer predicciones

```bash
docker-compose exec app poetry run predict
```

### 5. Visualizar en Frontend

Abre http://localhost:8501 en tu navegador (si usas Docker) o:

```bash
poetry run streamlit run src/runner_air_planner/frontend/streamlit_app.py
```

## ğŸ“ˆ Dataset para ML

El dataset final (`ml_dataset_accumulated.csv`) contiene **~42 features**:

- **Contaminantes**: `no2`, `o3`, `pm10`, `pm25`, `no`, `nox`, `so2`, `co`
- **EstaciÃ³n**: cÃ³digo, nombre, tipo (TrÃ¡fico/Suburbana), coordenadas
- **Temporales**: hora, dÃ­a semana, mes, `is_weekend`, `is_rush_hour`
- **MeteorolÃ³gicas**: temperatura, humedad, viento, cÃ³digo tiempo
- **Sinergias**: `wind_*_synergy`, `temp_o3_synergy`, `air_quality_index`, etc.

## ğŸ”Œ APIs Utilizadas

- **Calidad del Aire Madrid**: `https://datos.madrid.es/egob/catalogo/212531-12751102-calidad-aire-tiempo-real.json`
- **Open-Meteo**: `https://api.open-meteo.com/v1/forecast` (gratuita, sin API key)

## ğŸ“‹ Requisitos

- **Docker & Docker Compose** (recomendado)
- O **Python 3.11+** y **Poetry** (para desarrollo local)

## ğŸ“ Notas

- Los datos se acumulan automÃ¡ticamente, eliminando duplicados
- Por defecto se mantienen Ãºltimos 30 dÃ­as de historial
- El dataset se actualiza incrementalmente con cada ejecuciÃ³n
- Los modelos entrenados se guardan en `data/models/`

## ğŸ› ï¸ Comandos Makefile

```bash
make up          # Levantar app
make collect     # Recopilar datos
make train       # Entrenar modelo
make predict     # Hacer predicciones
make logs        # Ver logs
make shell       # Abrir shell
make down        # Detener
```

Ver `QUICKSTART.md` para mÃ¡s detalles.
